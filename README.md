# Ticket-Exchange-Sentiment-Analysis
The aim of this analysis is to shed light on the following question: What is the experience of BTS fans trading concert tickets on Twitter?

I was curious about exploring this question as a member of the BTS fandom. Due to overwhelming demand for BTS concert tickets, some fans who are unable to secure concert tickets during the pre-sale and general onsale, turn to social media to locate affordable fan-to-fan tickets for sale and/or trading. However, while there are some advantages of this method (potential for better prices, no re-sale ticket fees, community building), it can also be highly prone to fans getting scammed.

Thus, I wanted to run a text sentiment classifier on tweets from a BTS concert tickets Twitter trading account to measure the proportion of tweets with a negative sentiment as a measure of negative experiences of fans buying/trading tickets on social media. I chose to use VADER sentiment analyzer for this inquiry since I am analyzing text data from Twitter and this model was trained on social media text. I used Twitter API to obtain the text data from the analyzed Twitter account. Due to API access restrictions, I set up the tweet count to 200 (to round up) since I was only able to access 198 tweets at time. 

I first ran a few tests to get a sense of how the VADER classifier was evaluating the sentiments. The first two texts were just generic sentences and the last three are more specific to ticket scamming. As excepted, the classifier was able to detect both positive and negative tones for the first couple of tests. However, it didn't perform as well with the scam-specific sentences. Particularly, I tested a very common phrase to alert account users of a scammer: "Scammer alert". Unfortunately, the classifier didn't detect this sentence as negative (compound score: 0.296), suggesting that the classifier would underestimate the amount of negative tweets in reference to scams. I tested two other scam-related text: "Ticket scam", and "I got scammed". The classifier was able to detect the first one as negative, but misclassified the second one as neutral, again suggesting that negative tweets in relation to scams may be underestimated. Still, according to the threshold method selected for this analysis (more on this in the next paragraph), the classifier misclassified two of these scam-related texts as neutral and not positive, which at least suggests that the model may not misclassify scam-related tweets as positive.

I used the compound score to classify tweets as positive, negative, or neutral. The compound score is how the model measures overall sentiment and it uses a scale from -1 to 1. The closer a score is to -1, the more negative the classified text is considered. Similarly, the closer a score is to 1, the more positive the classified text is considered. To use a prediction selection method that evenly splits the range of values, I used the thresholds of -0.333 and 0.333. Specifically, I predicted texts as negative if the compound score was less than or equal to -0.333, neutral if the compound score was between -0.333 and 0.333, and positive if the compound score was greater than or equal to 0.333. Since "scammer alert" is such a common sentence use to alert users of accounts that have been confirmed to be from scammers and the earlier test showed that the classifier didn't detect the sentence as negative, I added a rule to clasify the sentiment of a tweet as negative if "scammer alert" was found in the text.

The results are displayed in a pie chart generated with Matplotlib. Current results are as follows: 22.2% positive, 62.1% neutral, and 15.7% negative. While I was able to include "scammer alert" tweets in the negative count, other tweets related to scams may have been missed as suggested in the earlier test, which could cause the negative count to be underestimated. It's also important to note that the "scammer alert" tweets usually consist of one tweet with an aggregated list of scammers, which may also lead to undercounting the negative percentage since it doesn't count each scammer in the list individually. To improve results, perhaps a sentiment classifier that is trained with concert ticket specific social media text data would be needed.
 
In general, the classifier found a relatively low percentage of negative tweets, but again, misclassification of tweets may have been an issue. In any case, fans using social media to buy/sell/trade concert tickets should still proceed with caution. 

This repository includes the present README file and a Jupyter Notebook with the Python code and results.
